{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic imports ✌\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import math, random\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "import sounddevice as sd\n",
    "import python_speech_features\n",
    "\n",
    "%matplotlib inline\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Finding speech sample 🤷‍🤷‍🤷‍\n",
    "class speech:\n",
    "    \n",
    "    def choose_random(self):\n",
    "        path = r\"C:\\Users\\Darius\\Desktop\\sound samples\\training data for RNN\\LibriSpeech\\train-clean-100\"\n",
    "        for i in range (0,3):\n",
    "            files = os.listdir(path)\n",
    "            index = random.randrange(0, len(files))\n",
    "            if  files[index].endswith('.txt'):\n",
    "                index = index + 1\n",
    "            path  = os.path.join(path, files[index])\n",
    "        file_path = path\n",
    "        self.sample, fs2 = sf.read(file_path)\n",
    "        \n",
    "        self.size = len(self.sample)\n",
    "        self.nfcc = python_speech_features.mfcc(self.sample,18000)\n",
    "\n",
    "    def show_sample(self):\n",
    "        print(file_path)\n",
    "        plt.plot(self.sample)\n",
    "    def listen_sample(self):\n",
    "        sd.play(self.sample) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding noise sample 🎉🎉🎉🎉🎷🎸🎶🎵🎵\n",
    "class noise:\n",
    "    def __init__(self,size):\n",
    "        self.size = size\n",
    "    \n",
    "    def choose_random(self):\n",
    "        path = r\"C:\\Users\\Darius\\Desktop\\sound samples\\training data for RNN\\rnnoise_contributions\"\n",
    "        files = os.listdir(path)\n",
    "        index = random.randrange(0, len(files))\n",
    "        if  files[index].endswith('.txt'):\n",
    "            index = index -1\n",
    "        file_path = os.path.join(path, files[index])\n",
    "        self.sample, fs = sf.read(file_path, channels=2, samplerate=24100,format='RAW', subtype='PCM_16')\n",
    "\n",
    "        i=0\n",
    "        while i!=1:\n",
    "            random_sequence = random.randrange(0,len(self.sample))\n",
    "            if random_sequence + self.size < len(self.sample):\n",
    "                i=1\n",
    "        self.sample = self.sample[random_sequence:]\n",
    "        self.sample = self.sample[:self.size ,:1]\n",
    "        \n",
    "        self.nfcc = python_speech_features.mfcc(self.sample,18000)\n",
    "        \n",
    "    def show_sample():\n",
    "        print(file_path)\n",
    "        plt.plot(self.sample)\n",
    "    def listen_sample(self):\n",
    "        sd.play(self.sample) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making input sample  🎵🎵🤷‍🤷‍\n",
    "class combined_samples:\n",
    "    def __init__(self,speech_sample,noise_sample):\n",
    "        self.speech_sample = speech_sample\n",
    "        self.noise_sample  = noise_sample\n",
    "    \n",
    "    def combine_samples(self):\n",
    "        self.sample = [len(self.speech_sample)] * 0\n",
    "        self.sample = np.empty([len(self.speech_sample)])\n",
    "\n",
    "        for i in range(len(self.speech_sample)):\n",
    "            self.sample[i] = self.speech_sample[i] + self.noise_sample[i]\n",
    "        \n",
    "        self.size = len(self.sample)\n",
    "        self.nfcc = python_speech_features.mfcc(self.sample,18000)\n",
    "        \n",
    "    def show_sample(self):\n",
    "        plt.plot(self.sample)\n",
    "    def listen_sample(self):\n",
    "        sd.play(self.sample) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Data\n",
    "class training_data:\n",
    "    def get_data(self):\n",
    "        self.speechD = speech()\n",
    "        self.speechD.choose_random()\n",
    "        \n",
    "        self.noiseD = noise(self.speechD.size)\n",
    "        self.noiseD.choose_random()\n",
    "        \n",
    "        self.combined = combined_samples(self.speechD.sample , self.noiseD.sample)\n",
    "        self.combined.combine_samples()\n",
    "        \n",
    "        self.input = self.combined.nfcc\n",
    "        self.output= self.speechD.nfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = training_data()\n",
    "d.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomRNN(\n",
       "  (rnn): GRU(2, 36, batch_first=True, dropout=0.1, bidirectional=True)\n",
       "  (linear): Linear(in_features=72, out_features=2, bias=True)\n",
       "  (act): Tanh()\n",
       ")"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating The GRU NN\n",
    "\n",
    "input_dim = 2\n",
    "hidden_size = 36\n",
    "num_layers = 2\n",
    "\n",
    "bidirectional = True\n",
    "if bidirectional:\n",
    "    num_directions = 2\n",
    "else:\n",
    "    num_directions = 1\n",
    "class CustomRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(CustomRNN, self).__init__()\n",
    "        self.rnn = nn.GRU(input_size=input_size, hidden_size=hidden_size, \n",
    "                          batch_first=True, bidirectional=bidirectional, dropout=0.1)\n",
    "        self.linear = nn.Linear(hidden_size*num_directions, output_size, )\n",
    "        self.act = nn.Tanh()\n",
    "    def forward(self, x):\n",
    "        pred, hidden = self.rnn(x, None)\n",
    "        pred = self.act(self.linear(pred)).view(pred.data.shape[0], -1, 1)\n",
    "        return pred\n",
    "    \n",
    "r= CustomRNN(input_dim, hidden_size, input_dim)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-176-0e324ca55f0f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;31m#inp = Variable(torch.Tensor(d.input.reshape((d.input.shape[0], -1, 2)), requires_grad=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;31m#out = Variable(torch.Tensor(d.output.reshape((d.output.shape[0], -1, 2)) )\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mpredictions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\apps\\Miniconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 477\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    478\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-175-3d57ed903f84>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mact\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTanh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mact\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\apps\\Miniconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 477\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    478\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\apps\\Miniconda\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    158\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m             \u001b[0mbatch_sizes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m             \u001b[0mmax_batch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_first\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'int' object is not callable"
     ]
    }
   ],
   "source": [
    "#Training the NN\n",
    "\n",
    "# Storing predictions per iterations to visualise later\n",
    "predictions = []\n",
    "\n",
    "optimizer = torch.optim.Adam(r.parameters(), lr=1e-2)\n",
    "loss_func = nn.L1Loss()\n",
    "\n",
    "for t in range(20):\n",
    "    hidden = None\n",
    "    #inp = Variable(torch.Tensor(d.input.reshape((d.input.shape[0], -1, 2)), requires_grad=True)\n",
    "    #out = Variable(torch.Tensor(d.output.reshape((d.output.shape[0], -1, 2)) )\n",
    "    pred = r(d.input)\n",
    "    optimizer.zero_grad()\n",
    "    predictions.append(pred.data.numpy())\n",
    "    loss = loss_func(pred, d.output)\n",
    "    if t%20==0:\n",
    "        print(t, loss.data[0])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    d.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test the NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
