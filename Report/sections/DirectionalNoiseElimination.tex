\chapter{Directional Noise Elimination}\label{ch:directional}
This chapter deals with directional filtering. In the beginning, the prerequisites for 
the filtering idea are presented. Afterwards, the actual filtering idea is shown and explained.
In the end, the results are presented, and a conclusion is drawn.
\section{Concept}
Figure \ref{fig:2sources} shows a scenario where directional filtering could be used.
Source 1 and Source 2 are both talking simultaneously. At the origin, two microphones,
left (L) and right (R) are fixed and recording.

\begin{figure}[htp]
	\centering
	\includegraphics[width=0.65\textwidth]{Illustrations/2sources.jpg}
	\caption{Two Persons Talking}
	\label{fig:2sources}
\end{figure}

\todo[inline]{maybe redo this, to eliminate middle line and write Origin}
Due to the nature of the setup, the microphones will record  both the speakers.
However, both microphones record two persons talking. As a consequence, each microphone
returns a soundwave containing two signals. The aim is to filter out one of them
by only using the two soundwaves available.

In order to be able to do this, one assumption needs to be made. That is, that the 
angle at which each source is located, is known.

\begin{figure}[htp]
	\centering
	\includegraphics[width=0.67\textwidth]{Illustrations/2sourcesWangles.jpg}
	\caption{Two Persons Talking With Known Angles}
	\label{fig:2sourcesWangles}
\end{figure}

Figure \ref{fig:2sourcesWangles} represents the same scenario. However this time, the angles
of the sound sources are known. The Sources and the Origin are represented with coordinates.
This helps in determining the formulas that are needed in order to obtain the delay in samples.

\begin{figure}[htp]
	\centering
	\includegraphics[width=0.67\textwidth]{Illustrations/2sourcesWanglesAndPossition.jpg}
	\caption{Two Persons Talking With Known Angles}
	\label{fig:2sourcesWanglesAndPossition}
\end{figure}

\newpage

Figure \ref{fig:zoomedin1} represents the delay between the two signals. One advantage
is represented by the fact that, no matter the distance of the source, the delay between the
signals is always the same. The delay in samples is only dependent on the distance between the mics.
By knowing the angle, the sampling frequnecy and the travelling speed of sound, the delay in 
samples can be determined. By increasing the distance between the microphones, greater accuracy 
could be obtained. However this would also result in a bigger difference in terms of signal gain.
One signal would be significantly louder than the other to the point where filtering would not work.


\begin{figure}[htp]
	\centering
	\includegraphics[width=0.65\textwidth]{Illustrations/delayDrawingForEquations.jpg}
	\caption{Delay}
	\label{fig:zoomedin1}
\end{figure}

\newpage
\section{Mathematical Solution}

Figure \ref{fig:zoomedin2} is a simplified version of Figure \ref{fig:zoomedin1} in order to better
understand the mathematical proof of finding the delay in number of samples.
\begin{figure}[htp]
	\centering
	\includegraphics[width=1\textwidth]{Illustrations/mathematicalShit.jpg}
	\caption{Mathematical Interpretation}
	\label{fig:zoomedin2}
\end{figure}

Firstly, the distances SR and SL must be determined. This can be found by employing 
basic trigonometry. This is done by independently finding out the sides of the triangles
SyL  and SyR.

\begin{equation}
	yR = sin(\theta) - \dfrac{d}{2} 
\end{equation}

\begin{equation}
	yL = sin(\theta) + \dfrac{d}{2}
\end{equation}

After the x-coordinates are determined, h is needed in order to calculate the y-coordinates.

\begin{equation}
	h = cos(\theta)
\end{equation}

\newpage
Lastly, the sides SR and SL are determined.

\begin{equation}
	SR = \sqrt{h^2 + yR^2}
\end{equation}

\begin{equation}
	SL = \sqrt{h^2 + yL^2}
\end{equation}

Once the distances are known, the difference in distance between the signals can be found.

\begin{equation}
	delay = SL - SR
\end{equation}

At this moment, the delay is expressed in distance. By knowing the speed of sound, the amount of
time it takes to travel that distance can be found.

\begin{equation}
	delayInTime = \frac{delay}{speed of sound}
\end{equation}

The time, can be converted in amount of samples by multiplying it by the sampling frequency.

\begin{equation}
	delayInSamples = delayInTime * SamplingFrequncy
\end{equation}

\newpage
\section{Idea for filtering}
With the angles of both sources known, one or the other source can be isolated. The only 
sound source considered in this project was human voice. Therefore, the aim is to 
separate the two voices, by only using the sound samples recorded by both microphones. 
The data recorded by each microphone, contains two separate human speeches.
Figure XX explains the process. Afterwards, a more visual example will be discussed,
aimed at better describing the procedure. 

\begin{figure}[htp]
	\centering
	\includegraphics[width=1\textwidth]{Illustrations/IdeaDiagram.jpg}
	\caption{Idea diagram}
	\label{fig:IdeaDiagram}
\end{figure}

\todo[inline]{redo diagram}

Both microphones record the same data. The only two differences, are the delay in time,
and the gain difference. By shifting one recorded sample in order to match the other,
and subtracting the signals, the matched data is eliminated. This means that by aligning 
one speech, and then subtracting, the other speech is separated and obtained.

\newpage

\section{Visual Example}
A visual example is explained below. Actual differences can even be seen on the waveforms themselves.
The example is ideal, meaning there is no noise applied to the signals, and their purpose is to 
prove the idea.

\begin{figure}[htp]
	\centering
	\includegraphics[width=\textwidth]{Illustrations/source1.jpg}
	\caption{First Source}
	\label{fig:source1}
\end{figure}

Figure \ref{fig:source1} shows a simple sine wave. Source 1 is the original signal. Source 1-Right Shifted
is the same signal just shifted to the right by 240 samples.

\newpage

\begin{figure}[htp]
	\centering
	\includegraphics[width=\textwidth]{Illustrations/source2.jpg}
	\caption{Second Source}
	\label{fig:source2}
\end{figure}


Figure \ref{fig:source2} shows another sine wave, with a higher frequency and a lower amplitude. This 
represents the second source. Source 2 is the original signal. Source 2 - Left Shifted is the same signal
shifted to the left by 377 samples.

Next step involves adding the signals.

\begin{equation}
	Source1 + Source2LeftShifted = LeftMicrophone
	\label{eq:leftMicrophone}
\end{equation}


\begin{equation}
	Source1RightShifted + Source2 = RightMicrophone
	\label{eq:rightMicrophone}
\end{equation}

Equations \ref{eq:leftMicrophone} and \ref{eq:rightMicrophone} now have both signals from both sources.
To better understand the equations, recall the scenario initially presented, shown in Figure
\ref{fig:2sources2}.

\begin{figure}[htp]
	\centering
	\includegraphics[width=0.65\textwidth]{Illustrations/2sources.jpg}
	\caption{Two Persons Talking}
	\label{fig:2sources2}
\end{figure}

\newpage

$LeftMicrophone$ contains $Source1$ and $Source2LeftShifted$. $RightMicrophone$ contains $Source2$
and $Source1RightShifted$.


\newpage
\subsection{Filtering}
All of the directional filtering is done by applying the logic discussed before to the Matlab script.\\
Prior to shifting signals and filtering, we had to remove any delays, induced by hardware or software. This 
issue was resolved by starting every recording with loud, sharp sound like a clap or a finger snap right in 
the middle of the microphones. Using this sound in the beginning we could match loudest peaks, thus 
eliminating hardware and software induced delay. \\
To see if we can get the samples, which show that logic behind direction of delay is correct, we set up a 
recording with just one person first see figure \ref{fig:RanzvanRecSetup}.\\

\begin{figure}[htp]
	\centering
	\includegraphics[width=.7\textwidth]{Illustrations/razvanWithSetup.jpg}
	\caption{Setup for recording with a person}
	\label{fig:RanzvanRecSetup}
\end{figure}

Then we looked at collected data:\\
When person spoke from the center, (Figure \ref{fig:C}) shows that recordings match in phase. Green graph is 
data, captured by left microphone and yellow graph is data, captured by right microphone.
\begin{figure}[htp]
  \centering
  \includegraphics[width=0.75\linewidth]{Illustrations/DataC.png}
  \caption{Data from speaker in the center}
  \label{fig:C}
\end{figure}
\\
\\

When person spoke from the right, right microphone data led left microphone (Figure \ref{fig:R}), here blue graph is left microphone data and orange graph represents right microphone data.\\
\begin{figure}[htp]
  \centering
  \includegraphics[width=0.75\linewidth]{Illustrations/DataR.png}
  \caption{Data from speaker in the right side}
  \label{fig:R}
\end{figure}

When he spoke from the left, left microphone was leading the right (Figure \ref{fig:L}) pink graph is left microphone data and purple graph shows right microphone data.\\

 
\begin{figure}[htp]
  \centering
  \includegraphics[width=0.75\linewidth]{Illustrations/DataL.png}
  \caption{Data from speaker in the left side}
  \label{fig:L}
\end{figure}

\todo[inline]{"For range -1 to 1 20*log10(x) corresponds to dB" Mention?}
 

All of the directional filtering is done by applying the logic discussed in the Idea for filtering section to 
the Matlab script.\\
First we took data from the recording with only one person, shifted left microphone to match right microphone 
data in phase, then subtracted right microphone data from shifted left microphone data - got "Noise". To 
finish filtering we tried to subtract "Noise" from the Right microphone data.\\
After re-listening the output files from this filtering process (noise file and output file), we couldn't see 
any difference in the output file, compared to the original data. The noise file contained enough data to 
still hear what the person was saying. Our expectation was to hear relative silence in noise file and have a 
bit more isolated output file.
\todo[inline]{"Do we put graphs of noise, output and original data?}


 

\section{Conclusion}